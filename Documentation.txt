pip install notebook

Jupyter notebook >>> permet d'ouvrir la page qui reprÃ©sente l'environnement de travail

pip install pandas numpy matplotlib seaborn scikit-learn


Le churn, câ€™est tout simplement :

âŒ quand un client arrÃªte un service

Selon le contexte, Ã§a peut vouloir dire :

rÃ©silier un abonnement

ne plus payer

ne plus utiliser le service

partir chez un concurrent

ğŸ“Œ Churn = perte de client

Â  ğŸ‘‰ Objectif EXACT du projet :
PrÃ©dire si un client va quitter le service (churn = Yes) ou rester (churn = No)
Ã  partir de ses informations (Ã¢ge, anciennetÃ©, services, prix, etc.)

FormulÃ© encore plus simplement :

Ã€ partir des donnÃ©es client, peut-on deviner sâ€™il va annuler son abonnement ?

///////EXPLICATION COMMANDE
import pandas as pd
permet de faire un raccourci

df = pd.read_csv("data/telecom_churn.csv")
nouvelle variable df  pd(outils pandas renomme) read_csv permet de lire le fichier avec la destination mise entre crochet

df.head()
affiche les 5 premiÃ¨res lignes

df.shape
ca  donne le nombre de ligne et le nombre de colonnes

df.info()
ca donne le nombre

df.columns
affiche les colonnes
df**["Churn"].value_counts()**
le [churn] permet d acceder a la colonne churn on ne met pas de numero
value_counts() permet d afficher les differentes valeurs qui sont dans la colonne et leur nombre >>> lorsqu'on ajoute .plot(kind="bar")

.plot() â†’ dessiner un graphique
Â kind="bar" â†’ barres

df.groupby("Churn")["AccountWeeks"].mean()
groupby("Churn") permet de separer selon le churn donnc on as 2 sous tableau
mean() permet de faire les moyennes

columns est une information dÃ©jÃ  stockÃ©e

ce nâ€™est pas une action

Python te renvoie juste la liste des noms de colonnes

ğŸ‘‰ Donc pas de ().

df.isnull().sum()
isnull - repere les valeurs manquantes
sum() - il les compte

X = df.drop("Churn", axis=1)
drop("Churn") â†’ enlÃ¨ve la colonne Churn
axis=1 â†’ on supprime une colonne (pas une ligne)

////DEBUT MACHINE LEARNING
(from sklearn.model_selection import train_test_split) â€œJe veux utiliser un outil qui coupe mes donnÃ©es en train et test.â€
outil de scikit-learn
coupe les donnÃ©es proprement

X_train, X_test, y_train, y_test = train_test_split(
Â    X, y, test_size=0.2, random_state=42
)
ğŸ‘‰ â€œPrends les donnÃ©es X et les rÃ©ponses yâ€

test_size=0.2
ğŸ‘‰ â€œGarde 20 % des donnÃ©es pour le testâ€
ğŸ‘‰ donc 80 % pour apprendre
random_state=42 " 42 est juste une convention Ã§a pourrait Ãªtre 0, 1, 123, 999" Lâ€™important nâ€™est pas 42,
mais le fait dâ€™en mettre un.
ğŸ‘‰ â€œFais le dÃ©coupage toujours de la mÃªme faÃ§onâ€


on sÃ©pare les donnÃ©es pour ne pas tricher

train_test_split le fait proprement

test_size dÃ©cide du pourcentage de test

random_state fige le hasard

sans random_state â†’ rÃ©sultats variables

from sklearn.linear_model import LogisticRegression
model = LogisticRegression(max_iter=1000)  max_iter donne assez dâ€™itÃ©rations pour converger
model.fit(X_train, y_train)
cette commande vas generer un tableau qui represente juste les informations du modele au "propre"
y_pred = model.predict(X_test)
model.predict_proba(X_test)

from sklearn.metrics import accuracy_score

accuracy = accuracy_score(y_test, y_pred)
accuracy

from sklearn.metrics import confusion_matrix

confusion_matrix(y_test, y_pred)


from sklearn.metrics import recall_score

model_balanced = LogisticRegression(
Â    max_iter=1000,
Â    class_weight="balanced"
)


from sklearn.metrics import precision_score
precision_score(y_test, y_pred_balanced)


from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression

from sklearn.metrics import confusion_matrix, recall_score, precision_score, accuracy_score


pipeline = Pipeline(steps=[
    ("scaler", StandardScaler()),
    ("model", LogisticRegression(max_iter=1000, class_weight="balanced"))
])


















Â 
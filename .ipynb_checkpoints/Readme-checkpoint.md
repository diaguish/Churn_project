# Customer Churn Prediction

## ğŸ“Œ Objectif
LLâ€™objectif de ce projet Ã©tait de prÃ©dire le churn client Ã  partir de donnÃ©es tÃ©lÃ©com.

Une premiÃ¨re rÃ©gression logistique a montrÃ© une bonne accuracy mais un recall trÃ¨s faible, ce qui signifiait que la majoritÃ© des clients churners nâ€™Ã©taient pas dÃ©tectÃ©s.

Afin de rÃ©pondre Ã  la problÃ©matique mÃ©tier, le modÃ¨le a Ã©tÃ© rÃ©entraÃ®nÃ© en utilisant class_weight="balanced" pour accorder plus dâ€™importance Ã  la classe minoritaire (clients churners).

Cette approche a permis dâ€™augmenter fortement le recall (â‰ˆ 80 %), rÃ©duisant ainsi le nombre de churners ratÃ©s, au prix dâ€™une baisse de la precision (â‰ˆ 39 %).

Ce compromis est pertinent dans un contexte churn, oÃ¹ rater un client est plus coÃ»teux que gÃ©nÃ©rer une fausse alerte.

Les rÃ©sultats montrent quâ€™un modÃ¨le simple, bien interprÃ©tÃ© et alignÃ© avec les objectifs mÃ©tier, peut dÃ©jÃ  apporter une rÃ©elle valeur.


## ğŸ“Š Dataset
Le dataset utilisÃ© contient des informations sur des clients tÃ©lÃ©com :
- anciennetÃ© du client
- usage des services
- nombre dâ€™appels au service client
- facturation
- variable cible : `Churn` (0 = reste, 1 = quitte)

## ğŸ§  MÃ©thodologie
1. Analyse exploratoire des donnÃ©es (EDA)
2. Identification de la variable cible et des variables explicatives
3. SÃ©paration des donnÃ©es en train / test
4. EntraÃ®nement dâ€™un modÃ¨le de rÃ©gression logistique
5. Ã‰valuation avec accuracy, confusion matrix, recall et precision
6. AmÃ©lioration du modÃ¨le avec `class_weight="balanced"`

## ğŸ“ˆ RÃ©sultats
- Accuracy : ~78 %
- Recall : ~80 %
- Precision : ~39 %

Le modÃ¨le est volontairement optimisÃ© pour maximiser le recall afin de limiter le nombre de clients churners non dÃ©tectÃ©s, ce qui entraÃ®ne une augmentation des fausses alertes.

## ğŸ¯ Conclusion mÃ©tier
Dans un contexte churn, il est prÃ©fÃ©rable de dÃ©tecter un maximum de clients Ã  risque, mÃªme au prix de fausses alertes, car rater un client entraÃ®ne une perte directe.  
Le modÃ¨le proposÃ© rÃ©pond Ã  cet objectif et constitue une base solide pour une mise en production ou des amÃ©liorations futures.

## ğŸ”§ AmÃ©liorations possibles
- Ajustement du seuil de dÃ©cision
- Test de modÃ¨les plus complexes (Random Forest)
- IntÃ©gration de nouvelles variables
- Optimisation du compromis recall / precision

## ğŸ› ï¸ Technologies
- Python
- Pandas
- Scikit-learn
- Matplotlib / Seaborn

